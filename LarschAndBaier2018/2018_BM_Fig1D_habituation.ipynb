{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShellApp.pylab_import_all = False\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import fnmatch\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "if 'startDirMaster' not in locals():\n",
    "    startDirMaster=os.getcwd()\n",
    "\n",
    "propsFn=startDirMaster+'\\\\props.csv'\n",
    "props=pd.read_csv(propsFn, header=None, index_col=0, squeeze=True,delim_whitespace=True).to_dict()\n",
    "\n",
    "base=props['BaseDir']\n",
    "expFile=props['allExpFn']\n",
    "\n",
    "RawDataDir = os.path.join(base,props['RawDataDir'])+'\\\\'\n",
    "ProcessingDir = os.path.join(base,props['ProcessingDir'])+'\\\\Fig1D_habituation\\\\'\n",
    "outputDir = os.path.join(base,props['outputDir'])+'\\\\'\n",
    "\n",
    "if not os.path.isdir(ProcessingDir):\n",
    "    os.makedirs(ProcessingDir)\n",
    "if not os.path.isdir(outputDir):\n",
    "    os.makedirs(outputDir)\n",
    "\n",
    "os.chdir('..\\\\')\n",
    "import functions.matrixUtilities_joh as mu\n",
    "import matplotlib.pyplot as plt\n",
    "import models.experiment as xp\n",
    "import models.experiment_set as es\n",
    "import functions.paperFigureProps as pfp\n",
    "pfp.paper()\n",
    "inToCm=2.54\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info=pd.read_csv(expFile, sep=',')\n",
    "info=info[info.stimulusProtocol=='hab']\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect meta information and save to new csv file for batch processing\n",
    "\n",
    "aviPath=[]\n",
    "posPath=[]\n",
    "PLPath=[]\n",
    "expTime = []\n",
    "    \n",
    "for index,row in info.iterrows():\n",
    "    startDir=RawDataDir+row.path+'\\\\'\n",
    "    #startDir='D:\\\\data\\\\b\\\\2017\\\\'+row.path+'\\\\'\n",
    "    #if not os.path.isdir(startDir):\n",
    "    #    startDir='E:\\\\b\\\\2017\\\\'+row.path+'\\\\'\n",
    "        \n",
    "    posPath.append(glob.glob(startDir+'PositionTxt*.txt')[0])\n",
    "    PLPath.append(glob.glob(startDir+'PL*.txt')[0])\n",
    "    \n",
    "    head, tail = os.path.split(posPath[-1])\n",
    "    currTime=datetime.strptime(tail[-23:-4], '%Y-%m-%dT%H_%M_%S')\n",
    "    expTime.append(currTime)\n",
    "    \n",
    "info['txtPath']=posPath\n",
    "info['pairList']=PLPath\n",
    "\n",
    "info['epiDur'] = 29      # duration of individual episodes (default: 5 minutes)\n",
    "info['episodes'] = -1   # number of episodes to process: -1 to load all episodes (default: -1)\n",
    "info['inDish'] = 10#np.arange(len(posPath))*120     # time in dish before experiments started (default: 10)\n",
    "info['arenaDiameter_mm'] = 100 # arena diameter (default: 100 mm)\n",
    "info['minShift'] = 60 # minimum number of seconds to shift for control IAD\n",
    "info['episodePLcode'] = 0 # flag if first two characters of episode name encode animal pair matrix (default: 0)\n",
    "info['recomputeAnimalSize'] = 0 # flag to compute animals size from avi file (takes time, default: 1)\n",
    "info['SaveNeighborhoodMaps'] = 0 # flag to save neighborhood maps for subsequent analysis (takes time, default: 1)\n",
    "info['computeLeadership'] = 0 # flag to compute leadership index (takes time, default: 1)\n",
    "info['ComputeBouts'] = 0 # flag to compute swim bout frequency (takes time, default: 1)\n",
    "info['set'] = np.arange(len(posPath))   # experiment set: can label groups of experiments (default: 0)\n",
    "info['ProcessingDir']=ProcessingDir\n",
    "info['outputDir']=outputDir\n",
    "info['allowEpisodeSwitch']=1\n",
    "\n",
    "info['expTime']=expTime\n",
    "\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# physical interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoP=pd.read_csv(expFile, sep=',')\n",
    "infoP=infoP[infoP.stimulusProtocol=='habTP']\n",
    "infoP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posPath = []\n",
    "aviPath=[]\n",
    "bdGroupAll=[]\n",
    "bgAll=[]\n",
    "expTimeAll=[]\n",
    "\n",
    "for index,row in infoP.iterrows():\n",
    "    #currTime=datetime.strptime(row.date, '%Y%m%d%H%M%S')\n",
    "    DishDir=RawDataDir+row.path\n",
    "    #DishDir='D:\\\\data\\\\b\\\\2017\\\\'+row.path\n",
    "    \n",
    "    #if not os.path.isdir(DishDir):\n",
    "    #    DishDir='E:\\\\b\\\\2017\\\\'+row.path\n",
    "    for root, dirnames, filenames in os.walk(DishDir):\n",
    "        for filename in fnmatch.filter(filenames, '*nogaps*.txt'):\n",
    "            posPath.append(os.path.join(root, filename))\n",
    "            bdGroupAll.append('0 0')\n",
    "            bgAll.append(row.bd)\n",
    "            currTime=datetime.strptime(filename[-23:-4], '%Y-%m-%dT%H_%M_%S')\n",
    "            expTimeAll.append(currTime)\n",
    "        for filename in fnmatch.filter(filenames, '*split*.avi'):\n",
    "            aviPath.append(os.path.join(root, filename))\n",
    "\n",
    "\n",
    "infoPAll=pd.DataFrame({'txtPath': posPath})\n",
    "infoPAll['epiDur']=29\n",
    "infoPAll['bd']=bgAll\n",
    "infoPAll['bdGroup']=bdGroupAll\n",
    "infoPAll['episodes']=-1\n",
    "infoPAll['inDish']=10\n",
    "#info['stimulusProtocol']=8\n",
    "infoPAll['arenaDiameter_mm'] = 100 # arena diameter (default: 100 mm)\n",
    "infoPAll['minShift'] = 60 # minimum number of seconds to shift for control IAD\n",
    "infoPAll['episodePLcode'] = 0 # flag if first two characters of episode name encode animal pair matrix (default: 0)\n",
    "infoPAll['recomputeAnimalSize'] = 0 # flag to compute animals size from avi file (takes time, default: 1)\n",
    "infoPAll['SaveNeighborhoodMaps'] = 0 # flag to save neighborhood maps for subsequent analysis (takes time, default: 1)\n",
    "infoPAll['computeLeadership'] = 0 # flag to compute leadership index (takes time, default: 1)\n",
    "infoPAll['ComputeBouts'] = 0 # flag to compute swim bout frequency (takes time, default: 1)\n",
    "infoPAll['set'] = np.arange(len(posPath))   # experiment set: can label groups of experiments (default: 0)\n",
    "infoPAll['expTime']=expTimeAll\n",
    "\n",
    "infoPAll['ProcessingDir']=ProcessingDir\n",
    "infoPAll['outputDir']=outputDir\n",
    "infoPAll['allowEpisodeSwitch']=1\n",
    "\n",
    "infoPAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoVirtualPhysical=pd.concat([info,infoPAll],sort=True)\n",
    "\n",
    "csvFile=os.path.join(ProcessingDir,'Fig1D_habituation.csv')\n",
    "infoVirtualPhysical.to_csv(csvFile,encoding='utf-8')\n",
    "infoVirtualPhysical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def readExperiment(keepData=False):\n",
    "    tmp=es.experiment_set(csvFile=csvFile)\n",
    "    if keepData:\n",
    "        return tmp\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "expSet=readExperiment(keepData=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csvPath = []\n",
    "for f in [mu.splitall(x)[-1][:-4] for x in infoVirtualPhysical.txtPath]:\n",
    "    csvPath.append(glob.glob(ProcessingDir+f+'*siSummary*.csv')[0])\n",
    "\n",
    "\n",
    "df=pd.DataFrame()\n",
    "i=0\n",
    "for fn in csvPath:\n",
    "    print(fn)\n",
    "    tmp=pd.read_csv(fn,index_col=0,sep=',')\n",
    "    tmp.animalSet=i\n",
    "    tmp['animalIndexCont']=tmp.animalIndex+((i)*15)\n",
    "    df=pd.concat([df,tmp])\n",
    "    i+=1\n",
    "\n",
    "df=df[df['animalIndex']!=14]\n",
    "df=df[df['animalIndex'].isin(np.arange(0,14,2))]\n",
    "df['episode']='skype'\n",
    "print('df shape',df.shape)\n",
    "\n",
    "d=df.time\n",
    "r=datetime(2017,1,1)\n",
    "t2=[pd.to_datetime(x).replace(day=1,month=1)for x in df.time]\n",
    "\n",
    "t3=[(x-r)/pd.Timedelta('1 hour') for x in t2]\n",
    "df['t2']=t2\n",
    "df['t3']=t3\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c']=0\n",
    "df.loc[df.animalSet>8,'c']=4\n",
    "df.c[df.animalSet==1]=1\n",
    "df.c[df.animalSet==2]=2\n",
    "df.c[df.animalSet.isin([3,4,5,6,7,8])]=3\n",
    "\n",
    "df['c2']=1\n",
    "df.loc[df.animalSet>8,'c2']=0\n",
    "df.c2[df.animalSet==1]=1\n",
    "df.c2[df.animalSet==2]=1\n",
    "df.c2[df.animalSet.isin([3,4,5,6,7,8])]=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anList=df.animalIndexCont.unique()\n",
    "IADsArray=np.zeros((2*anList.shape[0],df.epiNr.unique().shape[0],10))*np.nan\n",
    "#expList=df.animalSet.unique()\n",
    "expList=np.arange(8)\n",
    "ai=0\n",
    "for e in expList:\n",
    "    dfTmp=df[df.animalSet==e]\n",
    "    anList=dfTmp.animalIndexCont.unique()\n",
    "    \n",
    "\n",
    "    for a in anList:\n",
    "        idx3=dfTmp.animalIndexCont==a\n",
    "        pl=np.where(idx3)[0]\n",
    "        print('computing: ',e,a,idx3.sum())\n",
    "        ep=0\n",
    "        for p in pl:\n",
    "            expIAD=np.array(expSet.experiments[e].pair[p].IADs())\n",
    "            expIADm=np.nanmean(expIAD,axis=1)\n",
    "\n",
    "            for i in range(9):\n",
    "                ShiftAttract=(expIADm[i]-expIADm[-1])/expIADm[i]\n",
    "                IADsArray[ai,ep,i]=ShiftAttract\n",
    "            ShiftAttract=(expIADm[:-1].mean()-expIADm[-1])/expIADm[:-1].mean()\n",
    "            IADsArray[ai,ep,9]=ShiftAttract\n",
    "            ep+=1\n",
    "        ai+=1\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IADsMean=IADsArray[:,:,9]\n",
    "IADsArray=IADsArray[:,:,:9]\n",
    "IADsArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isfinite(np.nanmean(IADsArray,axis=2)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp.paper()\n",
    "sns.set_palette('viridis',3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6/inToCm,4.5/inToCm))\n",
    "\n",
    "rav=IADsMean.ravel()\n",
    "\n",
    "h=ax.hist(rav[np.isfinite(rav)],bins=20)\n",
    "ax.set_xlabel('Control attraction in shifted pairs \\n 29 minutes of data each')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks([-.4,0,.4])\n",
    "ax.set_xlim([-.5,.5])\n",
    "#ax.text(.35,750,'Mean: '+\"{:1.3f}\".format(np.mean(IADsAll)),color='r')\n",
    "#ax.text(.35,650,'Std: '+\"{:1.3f}\".format(np.std(IADsAll)))\n",
    "#ax.axvline(0,linestyle=':',color='gray')\n",
    "ax.axvline(np.mean(IADsArray),linestyle=':',color='r')\n",
    "\n",
    "l,u=stats.t.interval(0.95, len(IADsArray.ravel())-1, loc=np.nanmean(IADsMean), scale=np.nanstd(IADsMean))\n",
    "ax.axvline(u,linestyle=':',color='k')\n",
    "ax.axvline(l,linestyle=':',color='k')\n",
    "#ax.text(.35,550,'CI95: '+\"{:0.3f}\".format(l)+'-'+\"{:1.3f}\".format(u))\n",
    "print(np.nanmean(IADsMean),np.nanstd(IADsMean),l,u)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI=np.zeros(24)\n",
    "CIan=np.ones(24)\n",
    "for i in range(24):\n",
    "    CI[i]=np.nanstd(np.nanmean(IADsArray[:,:i+1,:],axis=1).mean(axis=1))\n",
    "    CIan[i]=np.nanstd(np.nanmean(IADsMean[:,:i+1],axis=1))\n",
    "plt.plot(CI*2,'.')\n",
    "plt.plot(2*CIan,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp.paper()\n",
    "sns.set_palette('viridis',3)\n",
    "fig, ax = plt.subplots(figsize=(6/inToCm,4.5/inToCm))\n",
    "\n",
    "x=np.arange(1,900/30)\n",
    "ax.plot(x*30,\n",
    "        2*np.nanstd(np.nanmean(IADsArray,axis=2))/np.sqrt(x),\n",
    "        'r',\n",
    "        label='normal distribution',\n",
    "       linewidth=2)\n",
    "\n",
    "ax.plot(x[:24]*30,\n",
    "        CI[:24]*2,\n",
    "        '.k-',\n",
    "        label='data',\n",
    "        markerSize=5,\n",
    "       alpha=1)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Recording duration (Minutes)')\n",
    "ax.set_ylabel('Attraction CI95 +/-')\n",
    "ax.set_xlim([0,500])\n",
    "ax.set_ylim([0,.3])\n",
    "sns.despine()\n",
    "ax.set_xticks(np.arange(0,500,120));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI[0]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.tsplot(data=df, time=\"t3\",value=\"si\",unit=\"animalIndexCont\",condition='c',estimator=np.nanmean,interpolate=False,err_style=\"ci_bars\");\n",
    "plt.xlim([8,22])\n",
    "plt.ylim([0,.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp.paper()\n",
    "inToCm=2.54\n",
    "plt.figure(figsize=(9/inToCm,4.5/inToCm))\n",
    "ax = plt.gca()\n",
    "sns.tsplot(data=df, time=\"t3\",\n",
    "           value=\"si\",\n",
    "           unit=\"animalIndexCont\",\n",
    "           condition='c',\n",
    "           estimator=np.nanmean,\n",
    "           interpolate=True,\n",
    "           err_style=\"ci_bars\",\n",
    "           ax=ax)#,color=['k','r','r','r']);\n",
    "\n",
    "ax.set_xlim([9,23])\n",
    "ax.set_ylim([0,.8])\n",
    "sns.despine()\n",
    "ax.set_xlabel('time of day [hh]')\n",
    "ax.set_ylabel('attraction index')\n",
    "ax.set_title('adaptation')\n",
    "plt.legend(ncol=2,loc='lower center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t4']=np.round(df.t3*2)/2.0\n",
    "plt.figure(figsize=(9/inToCm,4.5/inToCm))\n",
    "ax = plt.gca()\n",
    "sns.tsplot(data=df.groupby(['animalIndexCont','c','t4']).mean().reset_index(), time=\"t4\",\n",
    "           value=\"si\",\n",
    "           unit=\"animalIndexCont\",\n",
    "           condition='c',\n",
    "           estimator=np.nanmean,\n",
    "           interpolate=True,\n",
    "           err_style=\"ci_bars\",\n",
    "           ax=ax);\n",
    "\n",
    "ax.set_xlim([9,23])\n",
    "ax.set_ylim([0,.8])\n",
    "sns.despine()\n",
    "ax.set_xlabel('time of day [hh]')\n",
    "ax.set_ylabel('attraction index')\n",
    "ax.set_title('adaptation')\n",
    "plt.legend(ncol=2,loc='lower center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix=((df.c==3)&(~df.t4.isin(df[df.c==4].t4.unique()))).values\n",
    "df2=df[~ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7/inToCm,4.5/inToCm))\n",
    "ax = plt.gca()\n",
    "sns.tsplot(data=df.groupby(['t4','c2','animalIndexCont']).mean().reset_index(), time=\"t4\",\n",
    "           value=\"si\",\n",
    "           unit=\"animalIndexCont\",\n",
    "           condition='c2',\n",
    "           estimator=np.nanmean,\n",
    "           interpolate=True,\n",
    "           #err_style=\"ci_bars\",\n",
    "           #ci='sd',\n",
    "           ax=ax,\n",
    "          color=['gray','k']);\n",
    "\n",
    "ax.set_xlim([9,23])\n",
    "ax.set_ylim([0,1])\n",
    "sns.despine()\n",
    "ax.set_xlabel('Time of day')\n",
    "ax.set_ylabel('Attraction')\n",
    "ax.set_yticks([0,0.5,1])\n",
    "\n",
    "ax.set_xticks([10,14,18,22])\n",
    "ax.set_xticklabels(['10am','2pm','6pm','10pm'])\n",
    "\n",
    "#ax.set_title('adaptation')\n",
    "L=plt.legend(loc='upper right',title='Interaction')\n",
    "L.get_texts()[0].set_text('Physical')\n",
    "L.get_texts()[1].set_text('Virtual')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7/inToCm,4.5/inToCm))\n",
    "CI95=CI[0]*2\n",
    "print('CI95:',CI95)\n",
    "\n",
    "ax = plt.gca()\n",
    "#ax.fill_between([0,30],[CI95],[-CI95],color='gray',alpha=0.4)\n",
    "\n",
    "sns.tsplot(data=df2.groupby(['t4','c2','animalIndexCont']).mean().reset_index(), time=\"t4\",\n",
    "           value=\"si\",\n",
    "           unit=\"animalIndexCont\",\n",
    "           condition='c2',\n",
    "           estimator=np.nanmean,\n",
    "           interpolate=True,\n",
    "           #err_style=\"ci_bars\",\n",
    "           #ci='sd',\n",
    "           ax=ax,\n",
    "          color=['gray','k']);\n",
    "\n",
    "ax.set_xlim([9,22])\n",
    "ax.set_ylim([-.15,1])\n",
    "sns.despine()\n",
    "ax.set_xlabel('Time of day')\n",
    "ax.set_ylabel('Attraction')\n",
    "ax.set_yticks([0,0.5,1])\n",
    "#plt.axhline(0,ls=':',color='k')\n",
    "plt.axhline(0,ls='-',color='k',linewidth=0.5)\n",
    "plt.axhline(CI95,ls='--',color='gray',linewidth=0.5)\n",
    "plt.axhline(-CI95,ls='--',color='gray',linewidth=0.5)\n",
    "ax.set_xticks([10,14,18,22])\n",
    "ax.set_xticklabels(['10am','2pm','6pm','10pm'])\n",
    "\n",
    "#ax.set_title('adaptation')\n",
    "L=plt.legend(loc='upper right',title='Interaction')\n",
    "L.get_texts()[0].set_text('Physical')\n",
    "L.get_texts()[1].set_text('Virtual')\n",
    "figPath=outputDir+'\\\\1D_physicalVsVirtual_adaptation.svg'\n",
    "plt.savefig(figPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.age.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from shutil import copy2\n",
    "\n",
    "def splitall(path):\n",
    "    allparts = []\n",
    "    while 1:\n",
    "        parts = os.path.split(path)\n",
    "        if parts[0] == path:  # sentinel for absolute paths\n",
    "            allparts.insert(0, parts[0])\n",
    "            break\n",
    "        elif parts[1] == path: # sentinel for relative paths\n",
    "            allparts.insert(0, parts[1])\n",
    "            break\n",
    "        else:\n",
    "            path = parts[0]\n",
    "            allparts.insert(0, parts[1])\n",
    "    return allparts\n",
    "\n",
    "\n",
    "\n",
    "for i,row in info.iterrows():\n",
    "    fn=row.txtPath\n",
    "    head, tail = os.path.split(fn)\n",
    "\n",
    "    copyList=[]\n",
    "    copyList.append(glob.glob(head+'\\\\ROI*.csv')[0])\n",
    "    copyList.append(glob.glob(head+'\\\\PositionTxt*.txt')[0])\n",
    "    copyList.append(glob.glob(head+'\\\\PL*.txt')[0])\n",
    "    copyList.append(glob.glob(head+'\\\\*anSize.csv')[0])\n",
    "    \n",
    "    for f in copyList:\n",
    "        print(f)\n",
    "        if f[0]=='E':\n",
    "            keepSlash=3\n",
    "        else:\n",
    "            keepSlash=4\n",
    "        toDirectory = \"e:\\\\b\\\\LarschAndBaier2018\\\\RawData\\\\\" + os.path.join(*splitall(f)[keepSlash:-1])+\"\\\\\"\n",
    "        #toDirectory = \"e:\\\\b\\\\LarschAndBaier2018\\\\RawData\\\\\" \n",
    "        if not os.path.isdir(toDirectory):\n",
    "            os.makedirs(toDirectory)\n",
    "        \n",
    "        copy2(f, toDirectory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from shutil import copy2\n",
    "\n",
    "def splitall(path):\n",
    "    allparts = []\n",
    "    while 1:\n",
    "        parts = os.path.split(path)\n",
    "        if parts[0] == path:  # sentinel for absolute paths\n",
    "            allparts.insert(0, parts[0])\n",
    "            break\n",
    "        elif parts[1] == path: # sentinel for relative paths\n",
    "            allparts.insert(0, parts[1])\n",
    "            break\n",
    "        else:\n",
    "            path = parts[0]\n",
    "            allparts.insert(0, parts[1])\n",
    "    return allparts\n",
    "\n",
    "\n",
    "for i,row in infoPAll.iterrows():\n",
    "    fn=row.txtPath\n",
    "    head, tail = os.path.split(fn)\n",
    "\n",
    "    copyList=[]\n",
    "    copyList.append(glob.glob(head+'\\\\bgMed*.csv')[0])\n",
    "    copyList.append(glob.glob(head+'\\\\*nogaps.txt')[0])\n",
    "    #copyList.append(glob.glob(head+'\\\\*anSize.csv')[0])\n",
    "    aviTime=glob.glob(head+'\\\\*.avi')[0][-18:-4]\n",
    "    aviTime=datetime.strptime(aviTime,'%Y%m%d%H%M%S')\n",
    "\n",
    "\n",
    "    for f in copyList:\n",
    "        print(f)\n",
    "        if f[0]=='E':\n",
    "            keepSlash=3\n",
    "        else:\n",
    "            keepSlash=4\n",
    "        toDirectory = \"e:\\\\b\\\\LarschAndBaier2018\\\\RawData\\\\\" + os.path.join(*splitall(f)[keepSlash:-1])+\"\\\\\"\n",
    "        #toDirectory = \"e:\\\\b\\\\LarschAndBaier2018\\\\RawData\\\\\" \n",
    "        if not os.path.isdir(toDirectory):\n",
    "            os.makedirs(toDirectory)\n",
    "        \n",
    "        copy2(f, toDirectory)\n",
    "        #os.chdir(toDirectory)\n",
    "        if 'nogaps.txt' in f:\n",
    "            \n",
    "            old=glob.glob(toDirectory+'\\\\*nogaps.txt')[0]\n",
    "            #t=datetime.strftime(row.expTime, '%Y-%m-%dT%H_%M_%S')\n",
    "            t=datetime.strftime(aviTime, '%Y-%m-%dT%H_%M_%S')\n",
    "            #t=aviTime#, '%Y%m%d%H%M%S'\n",
    "            new=old[:-4]+str(i).zfill(2)+\"_\"+t+'.txt'\n",
    "            os.rename(old,new)\n",
    "            print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
