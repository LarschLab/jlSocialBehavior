{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary analysis: Skype vs fixed trajectory\n",
    "## 4 experiments, 2 animals each responding to black disc moving on various paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to [trajectories](../trajectories for closed loop vs open loop_01.ipynb) used for stimulus movement.\n",
    "\n",
    "5 episodes, 10 minutes each:\n",
    "\n",
    "1. closed loop (skype) interaction (not feeding coordinates)\n",
    "2. open loop replay of previously recorded animal path\n",
    "3. (2) but moving at constant speed (re-sampled path)\n",
    "4. open loop circular path, constant speed\n",
    "5. (4) but speed values taken from real animal path\n",
    "\n",
    "generate each episode separately and then stitch together\n",
    "\n",
    "The pattern is repeated 5-20 times per animal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result: Animals are significantly more attracted to a disk moving at realistic speed distribution compared to constant speed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%config InteractiveShellApp.pylab_import_all = False\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import fnmatch\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "if 'startDirMaster' not in locals():\n",
    "    startDirMaster=os.getcwd()\n",
    "\n",
    "propsFn=startDirMaster+'\\\\props.csv'\n",
    "\n",
    "props=pd.read_csv(propsFn, header=None, index_col=0, squeeze=True,delim_whitespace=True).to_dict()\n",
    "\n",
    "base=props['BaseDir']\n",
    "expFile=props['allExpFn']\n",
    "\n",
    "RawDataDir = os.path.join(base,props['RawDataDir'])+'\\\\'\n",
    "ProcessingDir = os.path.join(base,props['ProcessingDir'])+'\\\\Fig2B_boutPilot\\\\'\n",
    "outputDir = os.path.join(base,props['outputDir'])+'\\\\'\n",
    "\n",
    "if not os.path.isdir(ProcessingDir):\n",
    "    os.makedirs(ProcessingDir)\n",
    "if not os.path.isdir(outputDir):\n",
    "    os.makedirs(outputDir)\n",
    "\n",
    "os.chdir('..\\\\')\n",
    "import functions.matrixUtilities_joh as mu\n",
    "import matplotlib.pyplot as plt\n",
    "import models.experiment as xp\n",
    "import models.experiment_set as es\n",
    "import functions.paperFigureProps as pfp\n",
    "pfp.paper()\n",
    "inToCm=2.54\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info=pd.read_csv(expFile, sep=',')\n",
    "info=info[info.stimulusProtocol=='pilot']\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# collect meta information and save to new csv file for batch processing\n",
    "\n",
    "#aviPath=[]\n",
    "posPath=[]\n",
    "PLPath=[]\n",
    "expTimeAll=[]\n",
    "bdGroupAll=[]\n",
    "bgAll=[]\n",
    "setAll=[]\n",
    "inDishAll=[]\n",
    "\n",
    "i=0\n",
    "for index,row in info.iterrows():\n",
    "    startDir=RawDataDir+row.path+'\\\\'\n",
    "    #startDir='D:\\\\data\\\\b\\\\2017\\\\'+row.path+'\\\\'\n",
    "    #if not os.path.isdir(startDir):\n",
    "    #    startDir='E:\\\\b\\\\2017\\\\'+row.path+'\\\\'\n",
    "\n",
    "    j=0\n",
    "    for root, dirnames, filenames in os.walk(startDir):\n",
    "        for filename in fnmatch.filter(filenames, '*PositionTxt_*.txt'):\n",
    "            posPath.append(os.path.join(root, filename))\n",
    "            try:\n",
    "                PLPath.append(glob.glob(root+'PL*.txt')[0])\n",
    "            except:\n",
    "                PLPath.append([])\n",
    "            bdGroupAll.append(row.bdGroup)\n",
    "            bgAll.append(row.bd)\n",
    "            currTime=datetime.strptime(filename[-23:-4], '%Y-%m-%dT%H_%M_%S')\n",
    "            \n",
    "            if j==0:\n",
    "                setStart=currTime\n",
    "                print('newSet')\n",
    "            j += 1\n",
    "            #print(j,currTime,setStart,(currTime-setStart).seconds/60.)\n",
    "            indish=((currTime-setStart).seconds/60. ) + 10\n",
    "            inDishAll.append(np.round(indish))\n",
    "            expTimeAll.append(currTime)\n",
    "            setAll.append(i)\n",
    "    i+=1\n",
    "    \n",
    "\n",
    "info=pd.DataFrame({'txtPath': posPath})\n",
    "info['epiDur']=10\n",
    "info['bd']=bgAll\n",
    "info['bdGroup']=bdGroupAll\n",
    "info['pairList']=PLPath\n",
    "\n",
    "info['epiDur'] = 10      # duration of individual episodes (default: 5 minutes)\n",
    "info['episodes'] = -1   # number of episodes to process: -1 to load all episodes (default: -1)\n",
    "info['inDish'] = inDishAll#np.arange(len(posPath))*120     # time in dish before experiments started (default: 10)\n",
    "info['arenaDiameter_mm'] = 100 # arena diameter (default: 100 mm)\n",
    "info['minShift'] = 60 # minimum number of seconds to shift for control IAD\n",
    "info['episodePLcode'] = 0 # flag if first two characters of episode name encode animal pair matrix (default: 0)\n",
    "info['recomputeAnimalSize'] = 0 # flag to compute animals size from avi file (takes time, default: 1)\n",
    "info['SaveNeighborhoodMaps'] = 0 # flag to save neighborhood maps for subsequent analysis (takes time, default: 1)\n",
    "info['computeLeadership'] = 0 # flag to compute leadership index (takes time, default: 1)\n",
    "info['ComputeBouts'] = 0 # flag to compute swim bout frequency (takes time, default: 1)\n",
    "info['set'] = setAll   # experiment set: can label groups of experiments (default: 0)\n",
    "info['ProcessingDir']=ProcessingDir\n",
    "info['outputDir']=outputDir\n",
    "info['allowEpisodeSwitch']=1\n",
    "info['expTime']=expTimeAll\n",
    "info['pxPmm']=0\n",
    "info.loc[info.set<4,'pxPmm']=8\n",
    "info.loc[info.set>=4,'episodePLcode']=1\n",
    "info.loc[info.set>=4,'epiDur']=5\n",
    "\n",
    "csvFile=os.path.join(ProcessingDir,'Fig2bPilot.csv')\n",
    "info.to_csv(csvFile,encoding='utf-8')\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def readExperiment(keepData=False):\n",
    "    tmp=es.experiment_set(csvFile=csvFile)\n",
    "    if keepData:\n",
    "        return tmp\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "expSet=readExperiment(keepData=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvPath = []\n",
    "for f in [mu.splitall(x)[-1][:-4] for x in info.txtPath]:\n",
    "    csvPath.append(glob.glob(ProcessingDir+f+'*siSummary*.csv')[0])\n",
    "\n",
    "\n",
    "df=pd.DataFrame()\n",
    "i=0\n",
    "for fn in csvPath:\n",
    "    print(fn)\n",
    "    tmp=pd.read_csv(fn,index_col=0,sep=',')\n",
    "    currSet=tmp.animalSet.values[0]\n",
    "    tmp['animalSetCont']=i\n",
    "    tmp['animalIndexCont']=tmp.animalIndex+(currSet*15)\n",
    "    tmp['animalIndexCont2']=tmp.animalIndex+(i*15)\n",
    "    \n",
    "    if tmp.animalSet.values[0]<4:\n",
    "        tmp=tmp[tmp['animalIndex']==0]\n",
    "        tmp.animalIndex=tmp['animalIndexCont']+np.mod(i,2)\n",
    "    #    tmp.animalIndex=np.mod(i,2)\n",
    "        \n",
    "        \n",
    "    df=pd.concat([df,tmp])\n",
    "    i+=1\n",
    "\n",
    "\n",
    "\n",
    "#df['episode']='skype'\n",
    "print('df shape',df.shape)\n",
    "\n",
    "d=df.time\n",
    "r=datetime(2017,1,1)\n",
    "t2=[pd.to_datetime(x).replace(day=1,month=1)for x in df.time]\n",
    "\n",
    "t3=[(x-r)/pd.Timedelta('1 hour') for x in t2]\n",
    "df['t2']=t2\n",
    "df['t3']=t3\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anList=df.animalIndexCont.unique()\n",
    "IADsArray=np.zeros((2*anList.shape[0],df.epiNr.unique().shape[0],10))*np.nan\n",
    "expList=df.animalSetCont.unique()\n",
    "#expList=np.arange(8)\n",
    "ai=0\n",
    "for e in expList:\n",
    "    dfTmp=df[df.animalSetCont==e]\n",
    "    anList=dfTmp.animalIndexCont.unique()\n",
    "    \n",
    "\n",
    "    for a in anList:\n",
    "        idx3=dfTmp.animalIndexCont==a\n",
    "        pl=np.where(idx3)[0]\n",
    "        print('computing: ',e,a,idx3.sum())\n",
    "        ep=0\n",
    "        for p in pl:\n",
    "            expIAD=np.array(expSet.experiments[e].pair[p].IADs())\n",
    "            expIADm=np.nanmean(expIAD,axis=1)\n",
    "\n",
    "            for i in range(9):\n",
    "                ShiftAttract=(expIADm[i]-expIADm[-1])/expIADm[i]\n",
    "                IADsArray[ai,ep,i]=ShiftAttract\n",
    "            ShiftAttract=(expIADm[:-1].mean()-expIADm[-1])/expIADm[:-1].mean()\n",
    "            IADsArray[ai,ep,9]=ShiftAttract\n",
    "            ep+=1\n",
    "        ai+=1\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IADsMean=IADsArray[:,:,9]\n",
    "IADsArray=IADsArray[:,:,:9]\n",
    "IADsArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isfinite(np.nanmean(IADsArray,axis=2)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp.paper()\n",
    "sns.set_palette('viridis',3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6/inToCm,4.5/inToCm))\n",
    "\n",
    "rav=IADsMean.ravel()\n",
    "\n",
    "h=ax.hist(rav[np.isfinite(rav)],bins=20)\n",
    "ax.set_xlabel('Control attraction in shifted pairs \\n 29 minutes of data each')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks([-.4,0,.4])\n",
    "ax.set_xlim([-.5,.5])\n",
    "#ax.text(.35,750,'Mean: '+\"{:1.3f}\".format(np.mean(IADsAll)),color='r')\n",
    "#ax.text(.35,650,'Std: '+\"{:1.3f}\".format(np.std(IADsAll)))\n",
    "#ax.axvline(0,linestyle=':',color='gray')\n",
    "ax.axvline(np.mean(IADsArray),linestyle=':',color='r')\n",
    "\n",
    "l,u=stats.t.interval(0.95, len(IADsArray.ravel())-1, loc=np.nanmean(IADsMean), scale=np.nanstd(IADsMean))\n",
    "ax.axvline(u,linestyle=':',color='k')\n",
    "ax.axvline(l,linestyle=':',color='k')\n",
    "#ax.text(.35,550,'CI95: '+\"{:0.3f}\".format(l)+'-'+\"{:1.3f}\".format(u))\n",
    "print(np.nanmean(IADsMean),np.nanstd(IADsMean),l,u)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI=np.zeros(100)\n",
    "CIan=np.ones(100)\n",
    "for i in range(100):\n",
    "    CI[i]=np.nanstd(np.nanmean(IADsArray[:,:i+1,:],axis=1).mean(axis=1))\n",
    "    CIan[i]=np.nanstd(np.nanmean(IADsMean[:,:i+1],axis=1))\n",
    "plt.plot(CI*2,'.')\n",
    "plt.plot(2*CIan,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp.paper()\n",
    "sns.set_palette('viridis',3)\n",
    "fig, ax = plt.subplots(figsize=(6/inToCm,4.5/inToCm))\n",
    "\n",
    "x=np.arange(1,400/5.)\n",
    "ax.plot(x*5,\n",
    "        2*np.nanstd(np.nanmean(IADsArray,axis=2))/np.sqrt(x),\n",
    "        'r',\n",
    "        label='Normal distribution',\n",
    "       linewidth=2)\n",
    "\n",
    "ax.plot(x[:10]*5,\n",
    "        CI[:10]*2,\n",
    "        '.k-',\n",
    "        label='ShiftPair data',\n",
    "        markerSize=5,\n",
    "       alpha=1)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Recording duration (Minutes)')\n",
    "ax.set_ylabel('Attraction CI95 +/-')\n",
    "ax.set_xlim([0,240])\n",
    "ax.set_ylim([0,.3])\n",
    "sns.despine()\n",
    "ax.set_xticks(np.arange(0,250,60));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.tsplot(data=df, time=\"t3\",value=\"si\",unit=\"animalIndexCont2\",condition='animalSet',estimator=np.nanmean,interpolate=False,err_style=\"ci_bars\");\n",
    "plt.xlim([8,22])\n",
    "plt.ylim([0,.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.tsplot(data=df[df['episode'].str.contains('skype')], time=\"inDishTime\",value=\"si\",unit=\"animalIndexCont2\",condition='animalSet',estimator=np.nanmean,interpolate=False,err_style=\"ci_bars\");\n",
    "plt.ylim([0,.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epiNames,df['epiNrOriginal']=np.unique(df.episode,return_inverse=True)\n",
    "print(epiNames)\n",
    "epiSort1=np.array([10,10,10,10,10,4,3,2,0,1])\n",
    "epiSort0=np.array([10,10,10,10,10,4,3,2,1,0])\n",
    "df['epiCorrect']=df.episode\n",
    "df.loc[df.animalSet==4,'epiCorrect']=epiNames[epiSort0[df.loc[df.animalSet==4,'epiNrOriginal']]]\n",
    "df.loc[df.animalSet==5,'epiCorrect']=epiNames[epiSort1[df.loc[df.animalSet==5,'epiNrOriginal']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=(df['inDishTime']<350) & (df['inDishTime']>60)  &(df.animalSet<4)\n",
    "episodeNames=df['epiCorrect'].unique()\n",
    "dfDR=df[idx]\n",
    "tmp=dfDR.groupby(['epiCorrect','animalIndex'],sort=True)['si']\n",
    "tmp2=tmp.mean().reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "plt.axhline(0)\n",
    "sns.boxplot(x=tmp2['epiCorrect'],y=tmp2['si'],notch=True)\n",
    "sns.swarmplot(x=tmp2['epiCorrect'],y=tmp2['si'],linewidth=1,edgecolor='gray')\n",
    "plt.ylim([-.1,.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=(df['inDishTime']<240) & (df['inDishTime']>60) & (df.animalIndex<14) &(df.animalSet==4)\n",
    "episodeNames=df['epiCorrect'].unique()\n",
    "dfDR=df[idx]\n",
    "tmp=dfDR.groupby(['epiCorrect','animalIndex'],sort=True)['si']\n",
    "tmp2=tmp.mean().reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "plt.axhline(0)\n",
    "sns.boxplot(x=tmp2['epiCorrect'],y=tmp2['si'],notch=True)\n",
    "sns.swarmplot(x=tmp2['epiCorrect'],y=tmp2['si'],linewidth=1,edgecolor='gray')\n",
    "plt.ylim([-.1,.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=(df['inDishTime']<240) & (df['inDishTime']>60) & (df.animalIndex<14) &(df.animalSet==5)\n",
    "episodeNames=df['epiCorrect'].unique()\n",
    "dfDR=df[idx]\n",
    "tmp=dfDR.groupby(['epiCorrect','animalIndex'],sort=True)['si']\n",
    "tmp2=tmp.mean().reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "plt.axhline(0)\n",
    "sns.boxplot(x=tmp2['epiCorrect'],y=tmp2['si'],notch=True)\n",
    "sns.swarmplot(x=tmp2['epiCorrect'],y=tmp2['si'],linewidth=1,edgecolor='gray')\n",
    "plt.ylim([-.1,.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attraction begins in the second episode and degrades after around 10 hours. The degradation could be habituation, fatigue or oxygen deprivation, these experiments have a lid. Limit subsequent analysis to a window of 50-550 minutes in arena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean attraction for each episode by day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average over all trials per episode (inflated n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=(df['inDishTime']<60*5) & (df['inDishTime']>50)\n",
    "df[idx].groupby('epiCorrect',sort=False)['si'].mean().plot.bar()\n",
    "mn=df[idx].groupby('epiCorrect',sort=False)['si'].mean()\n",
    "sd=df[idx].groupby('epiCorrect',sort=False)['si'].std()\n",
    "plt.errorbar(range(5), mn,yerr=sd,fmt='o',color='black')\n",
    "lims = plt.ylim()\n",
    "plt.ylim([0, lims[1]]) \n",
    "plt.ylabel('shoaling index +/- SD')\n",
    "plt.title('Attraction to black disk, closed loop skype vs. open loop \\n open loop: real vs. constant speed \\n n=8 animals x 5-10 trials each')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average all trials per animal per episode (now n = animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=df[idx].groupby(['epiCorrect','animalSet','animalIndex'],sort=False)['si'].mean()\n",
    "tmp=tmp.reset_index()\n",
    "\n",
    "tmp[\"anID\"] = tmp[\"animalSet\"].map(str) + tmp[\"animalIndex\"].map(str)\n",
    "tmp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotOrder=[0,1,2,4,3]\n",
    "labels, levels = pd.factorize(tmp.epiCorrect)\n",
    "\n",
    "newLevels=['pair','nPnB','nPcS','cPcS','cPnB']\n",
    "tmp['newEpi']=[newLevels[x] for x in labels]\n",
    "tmp['epiNr']=labels\n",
    "episodeNames=tmp['newEpi'].unique()\n",
    "\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## statistical analysis of differences between episode means\n",
    "\n",
    "Statistics were computed in PRISM, using the pivoted table tmp2 below.\n",
    "\n",
    "Note that skype condition effectively has half as much data as other stimuli bc. pair reciprocity.\n",
    "\n",
    "Therefore, limit ANOVA and post-hoc tests to passive stimuli.\n",
    "\n",
    "Using non-parametric ANOVA (friedman test) and Dunn post-hoc comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRISM Results:\n",
    "\n",
    "Table Analyzed\tData 1\n",
    "\t\n",
    "Friedman test\t\n",
    "  P value\t<0.0001\n",
    "  Exact or approximate P value?\tApproximate\n",
    "  P value summary\t****\n",
    "  Are means signif. different? (P < 0.05)\tYes\n",
    "  Number of groups\t4\n",
    "  Friedman statistic\t67.07\n",
    "\t\n",
    "Data summary\t\n",
    "  Number of treatments (columns)\t4\n",
    "  Number of subjects (rows)\t38\n",
    "\n",
    "\n",
    "Number of families\t1\t\t\t\t\n",
    "Number of comparisons per family\t6\t\t\t\t\n",
    "Alpha\t0.05\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "Dunn's multiple comparisons test\tRank sum diff.\tSignificant?\tSummary\tAdjusted P Value\t\n",
    "\t\t\t\t\t\n",
    "  fix_real_rSpeed vs. fix_real_cSpeed\t64\tYes\t****\t<0.0001\tB-C\n",
    "  fix_real_rSpeed vs. fix_circ_rSpeed\t22\tNo\tns\t0.3037\tB-D\n",
    "  fix_real_rSpeed vs. fix_circ_cSpeed\t82\tYes\t****\t<0.0001\tB-E\n",
    "  fix_real_cSpeed vs. fix_circ_rSpeed\t-42\tYes\t**\t0.0011\tC-D\n",
    "  fix_real_cSpeed vs. fix_circ_cSpeed\t18\tNo\tns\t0.6585\tC-E\n",
    "  fix_circ_rSpeed vs. fix_circ_cSpeed\t60\tYes\t****\t<0.0001\tD-E\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "Test details\tRank sum 1\tRank sum 2\tRank sum diff.\tn1\tn2\n",
    "\t\t\t\t\t\n",
    "  fix_real_rSpeed vs. fix_real_cSpeed\t137\t73\t64\t38\t38\n",
    "  fix_real_rSpeed vs. fix_circ_rSpeed\t137\t115\t22\t38\t38\n",
    "  fix_real_rSpeed vs. fix_circ_cSpeed\t137\t55\t82\t38\t38\n",
    "  fix_real_cSpeed vs. fix_circ_rSpeed\t73\t115\t-42\t38\t38\n",
    "  fix_real_cSpeed vs. fix_circ_cSpeed\t73\t55\t18\t38\t38\n",
    "  fix_circ_rSpeed vs. fix_circ_cSpeed\t115\t55\t60\t38\t38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2=tmp[['epiCorrect','si','anID']]\n",
    "tmp2=tmp2.pivot_table(columns='epiCorrect',index='anID',values='si')\n",
    "print(tmp2.shape)\n",
    "tmp2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2.reset_index().to_csv(outputDir+'Fig2B.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LowestConditionCount=5 # lowest number of repeats (in the first experiment, other experiments have more)\n",
    "CI95=CI[LowestConditionCount]*2\n",
    "print(LowestConditionCount, ' episode repeats per animal')\n",
    "print('CI95:',CI95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp2=tmp[(tmp.animalIndex!=14)&(((tmp.epiCorrect==tmp.epiCorrect.values[0])&(tmp.animalIndex.isin(np.arange(1,100,2))))==False)]\n",
    "\n",
    "sns.set_palette('Dark2',8)\n",
    "co=sns.color_palette(\"Dark2\", 8)\n",
    "\n",
    "col=['gray',co[0],co[1],co[0],co[1]]\n",
    "\n",
    "pfp.paper()\n",
    "inToCm=2.54\n",
    "fig, ax = plt.subplots(figsize=(9/inToCm,4/inToCm))\n",
    "#sns.boxplot(x='newEpi',y='si',data=tmp,width=0.5,order=episodeNames[plotOrder],palette=col,ax=ax,labels=['hi'])\n",
    "\n",
    "#mn=tmp.groupby('episode',sort=False)['si'].mean()\n",
    "#sd=tmp.groupby('episode',sort=False)['si'].std()\n",
    "#plt.errorbar(range(5), mn,yerr=sd,fmt='o',color='black')\n",
    "sns.pointplot(x='newEpi',\n",
    "              y='si',\n",
    "              hue='anID',\n",
    "              data=tmp2[tmp.epiCorrect!=tmp.epiCorrect.values[0]],\n",
    "              scale=0.2,\n",
    "              palette=['gray'],\n",
    "              order=episodeNames[plotOrder],\n",
    "              ax=ax,\n",
    "             zorder=0,\n",
    "              legend=False,\n",
    "             alpha=0.5)\n",
    "\n",
    "sns.stripplot(x='newEpi',\n",
    "              y='si',\n",
    "              data=tmp2,\n",
    "              palette=col,\n",
    "              order=episodeNames[plotOrder],\n",
    "              ax=ax,\n",
    "              s=3,\n",
    "             zorder=2,\n",
    "             alpha=0.5)\n",
    "\n",
    "sns.pointplot(x='newEpi',\n",
    "              y='si',\n",
    "              hue='anID',\n",
    "              data=tmp2[tmp.epiCorrect==tmp.epiCorrect.values[0]],\n",
    "              scale=0.1,\n",
    "              palette=['gray'],\n",
    "              order=episodeNames[plotOrder],\n",
    "              ax=ax,\n",
    "             zorder=1,\n",
    "              legend=False,\n",
    "             alpha=0.5)\n",
    "\n",
    "sns.pointplot(x='newEpi',\n",
    "              y='si',\n",
    "              data=tmp2,\n",
    "              order=episodeNames[plotOrder],\n",
    "              palette=col,\n",
    "              ax=ax,\n",
    "              ci =None,\n",
    "             zorder=1000,\n",
    "             edgecolor='k',\n",
    "             linewidth=1,\n",
    "             markers=['_'],\n",
    "             scale=4,\n",
    "              legend=False,\n",
    "             estimator=np.nanmean,\n",
    "             alpha=0.8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('Attraction')\n",
    "#plt.axhline(0,ls=':',color='k')\n",
    "plt.axhline(0,ls='-',color='k',linewidth=0.5)\n",
    "plt.axhline(CI95,ls='--',color='gray',linewidth=0.5)\n",
    "plt.axhline(-CI95,ls='--',color='gray',linewidth=0.5)\n",
    "plt.xlabel('')\n",
    "\n",
    "# statistical annotation, see below for stats!\n",
    "x1, x2 = 1, 2   # columns\n",
    "l=0.025\n",
    "y, h, col = tmp.si.max() + l, l, 'k'\n",
    "plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "plt.text((x1+x2)*.5, y+h, \"***\", ha='center', va='bottom', color=col,size=10)\n",
    "\n",
    "# statistical annotation\n",
    "x1, x2 = 3, 4   # columns\n",
    "l=0.025\n",
    "y, h, col = tmp.si.max() + l, l, 'k'\n",
    "plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "plt.text((x1+x2)*.5, y+h, \"***\", ha='center', va='bottom', color=col,size=10)\n",
    "\n",
    "ax.set_xticklabels(['Mutual \\n interaction',\n",
    "                    'Natural path \\n Natural bouts',\n",
    "                    'Natural path \\n Constant speed',\n",
    "                    'Synthetic path \\n Natural bouts',\n",
    "                    'Synthetic path \\n Constant speed'\n",
    "                   ])\n",
    "\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(10) \n",
    "    tick.label.set_rotation(45)\n",
    "    \n",
    "ax.tick_params(axis='x', which='major', pad=-5)\n",
    "ax.legend_.remove()\n",
    "sns.despine()\n",
    "#plt.tight_layout(pad=1, w_pad=0, h_pad=0);\n",
    "ax.set_yticks([0,.2,.4,.6]);\n",
    "#plt.xticks(rotation=30)\n",
    "#fig.set_size_inches(9/inToCm,4.5/inToCm)\n",
    "\n",
    "figPath=outputDir+'\\\\2B_PathAndSpeedPilot.svg'\n",
    "plt.savefig(figPath,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from shutil import copy2\n",
    "\n",
    "def splitall(path):\n",
    "    allparts = []\n",
    "    while 1:\n",
    "        parts = os.path.split(path)\n",
    "        if parts[0] == path:  # sentinel for absolute paths\n",
    "            allparts.insert(0, parts[0])\n",
    "            break\n",
    "        elif parts[1] == path: # sentinel for relative paths\n",
    "            allparts.insert(0, parts[1])\n",
    "            break\n",
    "        else:\n",
    "            path = parts[0]\n",
    "            allparts.insert(0, parts[1])\n",
    "    return allparts\n",
    "\n",
    "\n",
    "\n",
    "for i,row in info.iterrows():\n",
    "    fn=row.txtPath\n",
    "    head, tail = os.path.split(fn)\n",
    "\n",
    "    copyList=[]\n",
    "    #copyList.append(glob.glob(head+'\\\\ROI*.csv')[0])\n",
    "    copyList.extend(glob.glob(head+'\\\\PositionTxt_*.txt'))\n",
    "    #copyList.append(glob.glob(head+'\\\\PositionTxt_an1*.txt')[0])\n",
    "    try:\n",
    "        copyList.append(glob.glob(head+'\\\\PL*.txt')[0])\n",
    "        copyList.append(glob.glob(head+'\\\\*anSize.csv')[0])\n",
    "        copyList.append(glob.glob(head+'\\\\ROI*.csv')[0])\n",
    "    except:\n",
    "        pass\n",
    "    #copyList.append(glob.glob(head+'\\\\*anSize.csv')[0])\n",
    "    \n",
    "    for f in copyList:\n",
    "        print(f)\n",
    "        if f[0]=='E':\n",
    "            keepSlash=3\n",
    "        else:\n",
    "            keepSlash=4\n",
    "        toDirectory = \"e:\\\\b\\\\LarschAndBaier2018\\\\RawData\\\\\" + os.path.join(*splitall(f)[keepSlash:-1])+\"\\\\\"\n",
    "        #toDirectory = \"e:\\\\b\\\\LarschAndBaier2018\\\\RawData\\\\\" \n",
    "        if not os.path.isdir(toDirectory):\n",
    "            os.makedirs(toDirectory)\n",
    "        \n",
    "        copy2(f, toDirectory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
