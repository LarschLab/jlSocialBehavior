{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShellApp.pylab_import_all = False\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import fnmatch\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "propsFn='props.csv'\n",
    "props=pd.read_csv(propsFn, header=None, index_col=0, squeeze=True,delim_whitespace=True).to_dict()\n",
    "\n",
    "base=props['BaseDir']\n",
    "expFile=props['allExpFn']\n",
    "\n",
    "RawDataDir = os.path.join(base,props['RawDataDir'])+'\\\\'\n",
    "ProcessingDir = os.path.join(base,props['ProcessingDir'])+'\\\\Fig1D_habituation\\\\'\n",
    "outputDir = os.path.join(base,props['outputDir'])+'\\\\'\n",
    "\n",
    "if not os.path.isdir(ProcessingDir):\n",
    "    os.makedirs(ProcessingDir)\n",
    "if not os.path.isdir(outputDir):\n",
    "    os.makedirs(outputDir)\n",
    "\n",
    "os.chdir('..\\\\')\n",
    "import functions.matrixUtilities_joh as mu\n",
    "import matplotlib.pyplot as plt\n",
    "import models.experiment as xp\n",
    "import models.experiment_set as es\n",
    "import functions.paperFigureProps as pfp\n",
    "pfp.paper()\n",
    "inToCm=2.54\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info=pd.read_csv(expFile, sep=',')\n",
    "info=info[info.stimulusProtocol=='hab']\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect meta information and save to new csv file for batch processing\n",
    "\n",
    "aviPath=[]\n",
    "posPath=[]\n",
    "PLPath=[]\n",
    "expTime = []\n",
    "    \n",
    "for index,row in info.iterrows():\n",
    "    startDir=RawDataDir+row.path+'\\\\'\n",
    "    #startDir='D:\\\\data\\\\b\\\\2017\\\\'+row.path+'\\\\'\n",
    "    #if not os.path.isdir(startDir):\n",
    "    #    startDir='E:\\\\b\\\\2017\\\\'+row.path+'\\\\'\n",
    "        \n",
    "    posPath.append(glob.glob(startDir+'PositionTxt*.txt')[0])\n",
    "    PLPath.append(glob.glob(startDir+'PL*.txt')[0])\n",
    "    \n",
    "    head, tail = os.path.split(posPath[-1])\n",
    "    currTime=datetime.strptime(tail[-23:-4], '%Y-%m-%dT%H_%M_%S')\n",
    "    expTime.append(currTime)\n",
    "    \n",
    "info['txtPath']=posPath\n",
    "info['pairList']=PLPath\n",
    "\n",
    "info['epiDur'] = 29      # duration of individual episodes (default: 5 minutes)\n",
    "info['episodes'] = -1   # number of episodes to process: -1 to load all episodes (default: -1)\n",
    "info['inDish'] = 10#np.arange(len(posPath))*120     # time in dish before experiments started (default: 10)\n",
    "info['arenaDiameter_mm'] = 100 # arena diameter (default: 100 mm)\n",
    "info['minShift'] = 60 # minimum number of seconds to shift for control IAD\n",
    "info['episodePLcode'] = 0 # flag if first two characters of episode name encode animal pair matrix (default: 0)\n",
    "info['recomputeAnimalSize'] = 0 # flag to compute animals size from avi file (takes time, default: 1)\n",
    "info['SaveNeighborhoodMaps'] = 0 # flag to save neighborhood maps for subsequent analysis (takes time, default: 1)\n",
    "info['computeLeadership'] = 0 # flag to compute leadership index (takes time, default: 1)\n",
    "info['ComputeBouts'] = 0 # flag to compute swim bout frequency (takes time, default: 1)\n",
    "info['set'] = np.arange(len(posPath))   # experiment set: can label groups of experiments (default: 0)\n",
    "info['ProcessingDir']=ProcessingDir\n",
    "info['outputDir']=outputDir\n",
    "info['allowEpisodeSwitch']=1\n",
    "\n",
    "info['expTime']=expTime\n",
    "\n",
    "\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# physical interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoP=pd.read_csv(expFile, sep=',')\n",
    "infoP=infoP[infoP.stimulusProtocol=='habTP']\n",
    "infoP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posPath = []\n",
    "aviPath=[]\n",
    "bdGroupAll=[]\n",
    "bgAll=[]\n",
    "expTimeAll=[]\n",
    "\n",
    "for index,row in infoP.iterrows():\n",
    "    #currTime=datetime.strptime(row.date, '%Y%m%d%H%M%S')\n",
    "    DishDir=RawDataDir+row.path\n",
    "    #DishDir='D:\\\\data\\\\b\\\\2017\\\\'+row.path\n",
    "    \n",
    "    #if not os.path.isdir(DishDir):\n",
    "    #    DishDir='E:\\\\b\\\\2017\\\\'+row.path\n",
    "    for root, dirnames, filenames in os.walk(DishDir):\n",
    "        for filename in fnmatch.filter(filenames, '*nogaps*.txt'):\n",
    "            posPath.append(os.path.join(root, filename))\n",
    "            bdGroupAll.append('0 0')\n",
    "            bgAll.append(row.bd)\n",
    "            currTime=datetime.strptime(filename[-23:-4], '%Y-%m-%dT%H_%M_%S')\n",
    "            expTimeAll.append(currTime)\n",
    "        for filename in fnmatch.filter(filenames, '*split*.avi'):\n",
    "            aviPath.append(os.path.join(root, filename))\n",
    "\n",
    "\n",
    "infoPAll=pd.DataFrame({'txtPath': posPath})\n",
    "infoPAll['epiDur']=29\n",
    "infoPAll['bd']=bgAll\n",
    "infoPAll['bdGroup']=bdGroupAll\n",
    "infoPAll['episodes']=-1\n",
    "infoPAll['inDish']=10\n",
    "#info['stimulusProtocol']=8\n",
    "infoPAll['arenaDiameter_mm'] = 100 # arena diameter (default: 100 mm)\n",
    "infoPAll['minShift'] = 60 # minimum number of seconds to shift for control IAD\n",
    "infoPAll['episodePLcode'] = 0 # flag if first two characters of episode name encode animal pair matrix (default: 0)\n",
    "infoPAll['recomputeAnimalSize'] = 0 # flag to compute animals size from avi file (takes time, default: 1)\n",
    "infoPAll['SaveNeighborhoodMaps'] = 0 # flag to save neighborhood maps for subsequent analysis (takes time, default: 1)\n",
    "infoPAll['computeLeadership'] = 0 # flag to compute leadership index (takes time, default: 1)\n",
    "infoPAll['ComputeBouts'] = 0 # flag to compute swim bout frequency (takes time, default: 1)\n",
    "infoPAll['set'] = np.arange(len(posPath))   # experiment set: can label groups of experiments (default: 0)\n",
    "infoPAll['expTime']=expTimeAll\n",
    "\n",
    "infoPAll['ProcessingDir']=ProcessingDir\n",
    "infoPAll['outputDir']=outputDir\n",
    "infoPAll['allowEpisodeSwitch']=1\n",
    "\n",
    "infoPAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoVirtualPhysical=pd.concat([info,infoPAll],sort=True)\n",
    "\n",
    "csvFile=os.path.join(ProcessingDir,'Fig1D_habituation.csv')\n",
    "infoVirtualPhysical.to_csv(csvFile,encoding='utf-8')\n",
    "infoVirtualPhysical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def readExperiment(keepData=False):\n",
    "    tmp=es.experiment_set(csvFile=csvFile)\n",
    "    if keepData:\n",
    "        return tmp\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "expSet=readExperiment(keepData=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csvPath = []\n",
    "for f in [mu.splitall(x)[-1][:-4] for x in infoVirtualPhysical.txtPath]:\n",
    "    csvPath.append(glob.glob(ProcessingDir+f+'*siSummary*.csv')[0])\n",
    "\n",
    "\n",
    "df=pd.DataFrame()\n",
    "i=0\n",
    "for fn in csvPath:\n",
    "    print(fn)\n",
    "    tmp=pd.read_csv(fn,index_col=0,sep=',')\n",
    "    tmp.animalSet=i\n",
    "    tmp['animalIndexCont']=tmp.animalIndex+((i)*15)\n",
    "    df=pd.concat([df,tmp])\n",
    "    i+=1\n",
    "\n",
    "df=df[df['animalIndex']!=14]\n",
    "df=df[df['animalIndex'].isin(np.arange(0,14,2))]\n",
    "df['episode']='skype'\n",
    "print('df shape',df.shape)\n",
    "\n",
    "d=df.time\n",
    "r=datetime(2017,1,1)\n",
    "t2=[pd.to_datetime(x).replace(day=1,month=1)for x in df.time]\n",
    "\n",
    "t3=[(x-r)/pd.Timedelta('1 hour') for x in t2]\n",
    "df['t2']=t2\n",
    "df['t3']=t3\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c']=0\n",
    "df.loc[df.animalSet>8,'c']=4\n",
    "df.c[df.animalSet==1]=1\n",
    "df.c[df.animalSet==2]=2\n",
    "df.c[df.animalSet.isin([3,4,5,6,7,8])]=3\n",
    "\n",
    "df['c2']=1\n",
    "df.loc[df.animalSet>8,'c2']=0\n",
    "df.c2[df.animalSet==1]=1\n",
    "df.c2[df.animalSet==2]=1\n",
    "df.c2[df.animalSet.isin([3,4,5,6,7,8])]=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.tsplot(data=df, time=\"t3\",value=\"si\",unit=\"animalIndexCont\",condition='c',estimator=np.nanmean,interpolate=False,err_style=\"ci_bars\");\n",
    "plt.xlim([8,22])\n",
    "plt.ylim([0,.7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp.paper()\n",
    "inToCm=2.54\n",
    "plt.figure(figsize=(9/inToCm,4.5/inToCm))\n",
    "ax = plt.gca()\n",
    "sns.tsplot(data=df, time=\"t3\",\n",
    "           value=\"si\",\n",
    "           unit=\"animalIndexCont\",\n",
    "           condition='c',\n",
    "           estimator=np.nanmean,\n",
    "           interpolate=True,\n",
    "           err_style=\"ci_bars\",\n",
    "           ax=ax)#,color=['k','r','r','r']);\n",
    "\n",
    "ax.set_xlim([9,23])\n",
    "ax.set_ylim([0,.8])\n",
    "sns.despine()\n",
    "ax.set_xlabel('time of day [hh]')\n",
    "ax.set_ylabel('attraction index')\n",
    "ax.set_title('adaptation')\n",
    "plt.legend(ncol=2,loc='lower center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t4']=np.round(df.t3*2)/2.0\n",
    "plt.figure(figsize=(9/inToCm,4.5/inToCm))\n",
    "ax = plt.gca()\n",
    "sns.tsplot(data=df.groupby(['animalIndexCont','c','t4']).mean().reset_index(), time=\"t4\",\n",
    "           value=\"si\",\n",
    "           unit=\"animalIndexCont\",\n",
    "           condition='c',\n",
    "           estimator=np.nanmean,\n",
    "           interpolate=True,\n",
    "           err_style=\"ci_bars\",\n",
    "           ax=ax);\n",
    "\n",
    "ax.set_xlim([9,23])\n",
    "ax.set_ylim([0,.8])\n",
    "sns.despine()\n",
    "ax.set_xlabel('time of day [hh]')\n",
    "ax.set_ylabel('attraction index')\n",
    "ax.set_title('adaptation')\n",
    "plt.legend(ncol=2,loc='lower center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix=((df.c==3)&(~df.t4.isin(df[df.c==4].t4.unique()))).values\n",
    "df2=df[~ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7/inToCm,4.5/inToCm))\n",
    "ax = plt.gca()\n",
    "sns.tsplot(data=df.groupby(['t4','c2','animalIndexCont']).mean().reset_index(), time=\"t4\",\n",
    "           value=\"si\",\n",
    "           unit=\"animalIndexCont\",\n",
    "           condition='c2',\n",
    "           estimator=np.nanmean,\n",
    "           interpolate=True,\n",
    "           #err_style=\"ci_bars\",\n",
    "           #ci='sd',\n",
    "           ax=ax,\n",
    "          color=['gray','k']);\n",
    "\n",
    "ax.set_xlim([9,23])\n",
    "ax.set_ylim([0,1])\n",
    "sns.despine()\n",
    "ax.set_xlabel('Time of day')\n",
    "ax.set_ylabel('Attraction')\n",
    "ax.set_yticks([0,0.5,1])\n",
    "\n",
    "ax.set_xticks([10,14,18,22])\n",
    "ax.set_xticklabels(['10am','2pm','6pm','10pm'])\n",
    "\n",
    "#ax.set_title('adaptation')\n",
    "L=plt.legend(loc='upper right',title='Interaction')\n",
    "L.get_texts()[0].set_text('Physical')\n",
    "L.get_texts()[1].set_text('Virtual')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7/inToCm,4.5/inToCm))\n",
    "ax = plt.gca()\n",
    "sns.tsplot(data=df2.groupby(['t4','c2','animalIndexCont']).mean().reset_index(), time=\"t4\",\n",
    "           value=\"si\",\n",
    "           unit=\"animalIndexCont\",\n",
    "           condition='c2',\n",
    "           estimator=np.nanmean,\n",
    "           interpolate=True,\n",
    "           #err_style=\"ci_bars\",\n",
    "           #ci='sd',\n",
    "           ax=ax,\n",
    "          color=['gray','k']);\n",
    "\n",
    "ax.set_xlim([9,23])\n",
    "ax.set_ylim([0,1])\n",
    "sns.despine()\n",
    "ax.set_xlabel('Time of day')\n",
    "ax.set_ylabel('Attraction')\n",
    "ax.set_yticks([0,0.5,1])\n",
    "\n",
    "ax.set_xticks([10,14,18,22])\n",
    "ax.set_xticklabels(['10am','2pm','6pm','10pm'])\n",
    "\n",
    "#ax.set_title('adaptation')\n",
    "L=plt.legend(loc='upper right',title='Interaction')\n",
    "L.get_texts()[0].set_text('Physical')\n",
    "L.get_texts()[1].set_text('Virtual')\n",
    "figPath=outputDir+'\\\\1D_physicalVsVirtual_adaptation.svg'\n",
    "plt.savefig(figPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from shutil import copy2\n",
    "\n",
    "def splitall(path):\n",
    "    allparts = []\n",
    "    while 1:\n",
    "        parts = os.path.split(path)\n",
    "        if parts[0] == path:  # sentinel for absolute paths\n",
    "            allparts.insert(0, parts[0])\n",
    "            break\n",
    "        elif parts[1] == path: # sentinel for relative paths\n",
    "            allparts.insert(0, parts[1])\n",
    "            break\n",
    "        else:\n",
    "            path = parts[0]\n",
    "            allparts.insert(0, parts[1])\n",
    "    return allparts\n",
    "\n",
    "\n",
    "\n",
    "for i,row in info.iterrows():\n",
    "    fn=row.txtPath\n",
    "    head, tail = os.path.split(fn)\n",
    "\n",
    "    copyList=[]\n",
    "    copyList.append(glob.glob(head+'\\\\ROI*.csv')[0])\n",
    "    copyList.append(glob.glob(head+'\\\\PositionTxt*.txt')[0])\n",
    "    copyList.append(glob.glob(head+'\\\\PL*.txt')[0])\n",
    "    copyList.append(glob.glob(head+'\\\\*anSize.csv')[0])\n",
    "    \n",
    "    for f in copyList:\n",
    "        print(f)\n",
    "        if f[0]=='E':\n",
    "            keepSlash=3\n",
    "        else:\n",
    "            keepSlash=4\n",
    "        toDirectory = \"e:\\\\b\\\\LarschAndBaier2018\\\\RawData\\\\\" + os.path.join(*splitall(f)[keepSlash:-1])+\"\\\\\"\n",
    "        #toDirectory = \"e:\\\\b\\\\LarschAndBaier2018\\\\RawData\\\\\" \n",
    "        if not os.path.isdir(toDirectory):\n",
    "            os.makedirs(toDirectory)\n",
    "        \n",
    "        copy2(f, toDirectory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from shutil import copy2\n",
    "\n",
    "def splitall(path):\n",
    "    allparts = []\n",
    "    while 1:\n",
    "        parts = os.path.split(path)\n",
    "        if parts[0] == path:  # sentinel for absolute paths\n",
    "            allparts.insert(0, parts[0])\n",
    "            break\n",
    "        elif parts[1] == path: # sentinel for relative paths\n",
    "            allparts.insert(0, parts[1])\n",
    "            break\n",
    "        else:\n",
    "            path = parts[0]\n",
    "            allparts.insert(0, parts[1])\n",
    "    return allparts\n",
    "\n",
    "\n",
    "for i,row in infoPAll.iterrows():\n",
    "    fn=row.txtPath\n",
    "    head, tail = os.path.split(fn)\n",
    "\n",
    "    copyList=[]\n",
    "    copyList.append(glob.glob(head+'\\\\bgMed*.csv')[0])\n",
    "    copyList.append(glob.glob(head+'\\\\*nogaps.txt')[0])\n",
    "    #copyList.append(glob.glob(head+'\\\\*anSize.csv')[0])\n",
    "    aviTime=glob.glob(head+'\\\\*.avi')[0][-18:-4]\n",
    "    aviTime=datetime.strptime(aviTime,'%Y%m%d%H%M%S')\n",
    "\n",
    "\n",
    "    for f in copyList:\n",
    "        print(f)\n",
    "        if f[0]=='E':\n",
    "            keepSlash=3\n",
    "        else:\n",
    "            keepSlash=4\n",
    "        toDirectory = \"e:\\\\b\\\\LarschAndBaier2018\\\\RawData\\\\\" + os.path.join(*splitall(f)[keepSlash:-1])+\"\\\\\"\n",
    "        #toDirectory = \"e:\\\\b\\\\LarschAndBaier2018\\\\RawData\\\\\" \n",
    "        if not os.path.isdir(toDirectory):\n",
    "            os.makedirs(toDirectory)\n",
    "        \n",
    "        copy2(f, toDirectory)\n",
    "        #os.chdir(toDirectory)\n",
    "        if 'nogaps.txt' in f:\n",
    "            \n",
    "            old=glob.glob(toDirectory+'\\\\*nogaps.txt')[0]\n",
    "            #t=datetime.strftime(row.expTime, '%Y-%m-%dT%H_%M_%S')\n",
    "            t=datetime.strftime(aviTime, '%Y-%m-%dT%H_%M_%S')\n",
    "            #t=aviTime#, '%Y%m%d%H%M%S'\n",
    "            new=old[:-4]+str(i).zfill(2)+\"_\"+t+'.txt'\n",
    "            os.rename(old,new)\n",
    "            print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
